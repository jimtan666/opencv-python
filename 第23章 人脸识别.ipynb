{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atlantic-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "waiting-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图像\n",
    "def img_show(img):\n",
    "    if len(img.shape) == 3:\n",
    "        if img.shape[-1]==3:\n",
    "            b,g,r = cv2.split(img)\n",
    "            img = cv2.merge([r,g,b])\n",
    "        elif img.shape[-1]==4:\n",
    "            b,g,r,a = cv2.split(img)\n",
    "            img = img\n",
    "        plt.imshow(img)\n",
    "    elif len(img.shape) == 2:\n",
    "        plt.imshow(img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机加椒盐函数\n",
    "def salt(img,n):\n",
    "    # 循环添加n个椒盐\n",
    "    for k in range(n):\n",
    "        # 随机添加椒盐的坐标\n",
    "        i = int(np.random.random()*img.shape[0])\n",
    "        j = int(np.random.random()*img.shape[1])\n",
    "        # 若位灰度图\n",
    "        img[i,j] = 255\n",
    "        # 若为RGB图\n",
    "        img[i,j,0] = 255\n",
    "        img[i,j,0] = 255\n",
    "        img[i,j,0] = 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "social-wrist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 清洗锐化图片\n",
    "def cleaning(img):\n",
    "    bgr = cv2.split(img)\n",
    "    bgrNew = []\n",
    "    for c in bgr:\n",
    "        c = cv2.threshold(c,127,255,cv2.THRESH_BINARY)\n",
    "        bgrNew.append(c[1])\n",
    "    img = cv2.merge(bgrNew)\n",
    "    return img\n",
    "\n",
    "hand = cv2.imread(\"/Users/tanjun/Desktop/tanjun/opencv/hand.png\")\n",
    "cleaning(hand)\n",
    "cv2.imwrite(\"/Users/tanjun/Desktop/tanjun/opencv/hand.png\",hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-invalid",
   "metadata": {},
   "source": [
    "# 23.1 人脸检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "generic-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人脸检测中，主要任务是构造能够区分包含人脸实例和不包含人脸实例的分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-nicaragua",
   "metadata": {},
   "source": [
    "### 23.1.1 基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functional-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.级联分类器\n",
    "# 思路：将简单分类器按照一定顺序级联而成。（一级一级过滤分类）\n",
    "# 条件1 -F-> 负类\n",
    "#  ｜T\n",
    "# 条件2 -F-> 负类\n",
    "#  ｜T\n",
    "# 条件n -F-> 负类\n",
    "#  ｜T\n",
    "# 正类\n",
    "# 优势：开始用非常简单的判断排除明显不符合要求的实例，被排除的实例不参与下一次分类，提高分类速度\n",
    "\n",
    "# Haar级联分类器\n",
    "# opencv提供了训练好的Haar级联分类器用于人脸检测\n",
    "# Haar特征：\n",
    "# 垂直特征    水平特征     对角特征\n",
    "#  -1 1        -1         1 -1\n",
    "#               1         -1 1\n",
    "# Haar特征反应的是图像的灰度变化，他将像素划分为模块后求差值。\n",
    "# Haar特征用黑白两种矩形框组合成特征模版，在特征模版内，用白色矩形像素块内的像素和减去黑丝矩形像素块的像素和表示该模版的特征\n",
    "# 经过上述处理，人脸特征就可以用矩形框的差值简单表示。如眼睛颜色比脸颊深，鼻梁两侧颜色比鼻梁深等\n",
    "# Haar特征中的矩形框，有如下3个变量：\n",
    "# 矩形位置：矩形框要逐个像素划过整个图像后去每个位置的差值\n",
    "# 矩形大小：矩形大小可以任意调整\n",
    "# 矩形类型：垂直，水平，对角\n",
    "# 为提高效率，构造积分图，使用级联，并将Haar特征进一步划分为4类：见书P451\n",
    "# 4个边特征：\n",
    "# 8个线特征：\n",
    "# 2个中心点特征：\n",
    "# 1个对角特征：\n",
    "\n",
    "# 除此之外，opencv还提供了Hog特征和LBP算法的级联分类器。Hog级联分类器主要用于行人检测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-router",
   "metadata": {},
   "source": [
    "### 23.1.2 级联分类器的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "digital-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练级联分类器非常耗时，opencv提供了一些训练好的级联分类器共用户使用，这些分类器可以用来检测人脸，脸部特征，人类和其他物体\n",
    "# 这些级联分类器以XML文件形式存放在opencv源文件的data目录下，加在不同级联分类器的XML文件，就可以实现不同对象的检测\n",
    "# data：haarcascades,hogcascades,lbpcascades(Haarr级联分类器，HOG级联分类器，LBP级联分类器)\n",
    "# Haar级联分类器多达20多种，提供了多种对象的检测功能\n",
    "# XML文件名                             级联分类器类型\n",
    "# haarcascade_eye.xml                  眼睛检测\n",
    "# haarcascade_eye_tree_eyeglasses.xml  眼镜检测\n",
    "# haarcascade_mcs_nose.xml             鼻子检测\n",
    "# haarcascade_mcs_mouth.xml            嘴巴检测\n",
    "# haarcascade_smile.xml                表情检测\n",
    "# hogcascade_pedestrians.xml           行人检测\n",
    "# lbpcasecade_frontalface.xml          正面人脸检测\n",
    "# lbpcasecade_profileface.xml          人脸检测\n",
    "# lbpcasecade_sliverware.xml           金属检测\n",
    "\n",
    "# 加在级联分类器语法：\n",
    "# <CascadeClassifier object> = cv2.CascadeClassifier(filename)\n",
    "# faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 注意：如果通过anaconda中使用pip安装opencv，无法直接获取级联分类器xml文件，可通过两种方式获取：\n",
    "# 1）安装opencv后，在安装目录下的data文件夹内查找xml文件\n",
    "# 2）直接在网络上找到相应xml文件，下载并使用\n",
    "# 同样，使用opencv_createsamples.exe和opencv_traincascade.exe也需要采用上述方法获取xml文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-links",
   "metadata": {},
   "source": [
    "### 23.1.3 函数介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "burning-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv中，人脸检测使用cv2.CascadeClassifier.detectMultiScale()函数，它可以检测出图片中所有人脸：\n",
    "# object = cv2.CascadeClassifier.detectMultiScale(image[,scaleFactor[,minNeighbors[,flags[,minSize[,maxSize]]]]])\n",
    "# image：待检测图像\n",
    "# scaleFactor：在前后两次扫描中，搜索窗口的缩放比例\n",
    "# minNeighbors：构成检测目标的相邻矩形的最小数目，默认为3，意味着3个以上的检测标记存在时才认定为人脸存在\n",
    "# flags：同常被省略\n",
    "# minSize：目标的最小尺寸\n",
    "# maxSize：目标的最大尺寸\n",
    "# objects：目标对象的矩形框向量组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-belly",
   "metadata": {},
   "source": [
    "### 23.1.4 案例介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chubby-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "wzx = cv2.imread(\"/Users/tanjun/Desktop/tanjun/opencv/wzx.jpg\")\n",
    "gray = cv2.cvtColor(wzx,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 加在xml人脸检测器\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 调用函数detectMultiScale\n",
    "faces = faceCascade.detectMultiScale(gray,scaleFactor=1.15,minNeighbors=5,minSize=(5,5))\n",
    "\n",
    "# 逐个标注人脸\n",
    "for (x,y,w,h) in faces:\n",
    "#     cv2.rectangle(wzx,(x,y),(x+w,y+h),(0,0,255),2)  # 矩形标注\n",
    "    cv2.rectangle(wzx,(int((x+x+w)/2)),int((y+y+h)/2),int(w/2),(0,255,0),2)  # 圆形标注\n",
    "    \n",
    "# 显示结果\n",
    "img_show(wzx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-addition",
   "metadata": {},
   "source": [
    "# 23.2 LBPH人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "official-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv提供了3种人脸识别方法：LBPH，EigenFishfaces，Fisherfaces\n",
    "# LBPH（局部二值模式直方图）：基于LBP算法。LBP最早被作为纹理描述算子提出，由于在描述图像局部纹理特征效果出众得到广泛应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-hindu",
   "metadata": {},
   "source": [
    "### 23.2.1 基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extraordinary-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP算法的基本原理是，将像素点A的值与邻近的8个像素点值比较：\n",
    "# 如果A的值大于其邻近的像素点值，则得到0\n",
    "# 如果A的值小于其邻近的像素点值，则得到1\n",
    "# 最后，将像素点A与其周围的0个像素点比较得到的0，1值连起来，得到8位二进制序列，将二进制转换为十进制数作为A的LBP值\n",
    "\n",
    "# 例如：\n",
    "# 76与周围8点比较，得到二值图，再以任意一点开始，组成二值数（如从正上方开始，顺时针排列），再将二值数转十进制作为中心点的LBP值\n",
    "# 128 36  251     1 0 1\n",
    "# 48  76  9    >  0   0  > 01011001  > 89\n",
    "# 11  213 99      0 1 1\n",
    "# 对图像逐个像素用以上方式处理，得到LBP特征图想，这个特征图像的直方图称为LBPH，或称LBP直方图\n",
    "\n",
    "# 为了得到不同尺度下的纹理结构，还可使用圆形邻域，将计算扩大到任意大小的邻域内\n",
    "# 圆形邻域可用（P，R）表示，P表示圆形邻域内参与计算的像素点个数，R表示邻域的半径\n",
    "\n",
    "# 人脸的整体灰度由于首光线影响会经常发生变化，但人脸各部分间的相对灰度基本保持一致，LBP的主要思想就是用相对关系进行处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-diana",
   "metadata": {},
   "source": [
    "### 23.2.2 函数介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elder-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv中使用函数cv2.face.LBPHFaceRecognizer_create()生成LBPH识别器实例模型\n",
    "# 然后用cv2.face_FaceRecognizer.train()完成训练\n",
    "# 最后用cv2.face_FaceRecognizer.predict()完成人脸识别\n",
    "\n",
    "# 1.cv2.face.LBPHFaceRecognizer_create()\n",
    "# retval = cv2.face.LBPHFaceRecognizer_create([,radius[,neighbors[,grid_x[,grid_y[,threshold]]]]])\n",
    "# radius：半径，默认1\n",
    "# neighbors：邻域点个数，默认8\n",
    "# grid_x：将LBP特征图划分为一个个单元格时，每个单元格在水平方向上的像素个数，默认8，即在行方向以8个像素为单位分组\n",
    "# grid_y：将LBP特征图划分为一个个单元格时，每个单元格在竖直方向上的像素个数，默认8，即在列方向以8个像素为单位分组\n",
    "# threshold：在预测时使用的阈值。如果大于该阈值，就认为没有识别到任何目标对象\n",
    "\n",
    "# 2.cv2.face_Face_Recognizer.train()\n",
    "# None = cv2.face_Face_Recognizer.train(src,labels)\n",
    "# src：训练图像，用于训练的人脸图像\n",
    "# labels：标签，人脸图所对应的标签\n",
    "\n",
    "# 3.cv2.face_FaceRecognizer.predict()\n",
    "# label,confidence = cv2.face_FaceRecognizer.predict(src)\n",
    "# src：需要识别的人脸图像\n",
    "# label：返回识别结果标签\n",
    "# confidence：置信度评分。衡量识别结果与原有模型间的距离，0表示完全匹配，通常50一下可以接受，大于80差别较大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-consensus",
   "metadata": {},
   "source": [
    "### 23.2.3 案例介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rapid-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现一简单人脸识别\n",
    "\n",
    "# 训练集\n",
    "images = []\n",
    "images.append(cv2.imread('a1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('a2.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b2.png',cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "# 训练集标签\n",
    "labels = [0,0,1,1]\n",
    "\n",
    "# 测试图片\n",
    "predict_iamge = cv2.imread('a3.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(images,np.array(labels))\n",
    "label,confidence = recognizer.predict(predict_iamge)\n",
    "\n",
    "print(label,confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-cursor",
   "metadata": {},
   "source": [
    "# 23.3 EigenFace人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "irish-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EigenFace通常被称为特征脸，它使用主成分分析PCA方法将高维人脸数据处理称低维后进行数据分析，获取识别结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-trance",
   "metadata": {},
   "source": [
    "### 23.3.1 基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rough-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽去主成分，如圆的半径，直径，周长，面积，都可以用半径表示，所以半径就是主成分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-freeware",
   "metadata": {},
   "source": [
    "### 23.3.2 函数介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pointed-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv中使用函数cv2.face.EigenFaceRecognizer_create()生成LBPH识别器实例模型\n",
    "# 然后用cv2.face_FaceRecognizer.train()完成训练\n",
    "# 最后用cv2.face_FaceRecognizer.predict()完成人脸识别\n",
    "\n",
    "# 1.cv2.face.EigenFaceRecognizer_create()\n",
    "# retval = cv2.face.EigenFaceRecognizer_create([,num_components[,threshold]])\n",
    "# num_components：在PCA中要保留的分量个数，一般80个分量足够\n",
    "# threshold：人脸识别时采用的阈值\n",
    "\n",
    "# 2.cv2.face_Face_Recognizer.train()\n",
    "# None = cv2.face_Face_Recognizer.train(src,labels)\n",
    "# src：训练图像，用于训练的人脸图像\n",
    "# labels：标签，人脸图所对应的标签\n",
    "\n",
    "# 3.cv2.face_FaceRecognizer.predict()\n",
    "# label,confidence = cv2.face_FaceRecognizer.predict(src)\n",
    "# src：需要识别的人脸图像\n",
    "# label：返回识别结果标签\n",
    "# confidence：置信度评分。衡量识别结果与原有模型间的距离，0表示完全匹配，该参数通常在0-20000之间，低于5000则认为相当可靠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-carry",
   "metadata": {},
   "source": [
    "### 23.3.3 案例介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "promising-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "images = []\n",
    "images.append(cv2.imread('a1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('a2.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b2.png',cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "# 训练集标签\n",
    "labels = [0,0,1,1]\n",
    "\n",
    "# 测试图片\n",
    "predict_iamge = cv2.imread('a3.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "recognizer.train(images,np.array(labels))\n",
    "label,confidence = recognizer.predict(predict_iamge)\n",
    "\n",
    "print(label,confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-consumer",
   "metadata": {},
   "source": [
    "# 23.4 Fisherface人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "approximate-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA是EigenFace方法的核心，它找到了最大化数据总方差特征的线性组合。但缺点是缺失了一部分信息\n",
    "# Fisherface采用LDA（线性判断分析）实现人脸识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-party",
   "metadata": {},
   "source": [
    "### 23.4.1 基本原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "phantom-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性判断分析在对特征降为同时考虑类别信息。\n",
    "# 思路：在低维表示下，相同的类应该紧密地聚集在一起，不同的类别应该尽量分开：\n",
    "# 类别间差别尽可能大\n",
    "# 类别内差别尽可能小\n",
    "\n",
    "# 做线性判别分析时，首先将训练样本集投射到一条直线A上，让投影后的点满足：\n",
    "# 同类间的点尽可能地靠近\n",
    "# 异类间的点尽可能地满足\n",
    "# 做完投影后，经待测样本投影到直线A上，根据投影点的位置判定样本类别，就完成了识别\n",
    "\n",
    "# 线性判别分析就是要找到一条最优的投影点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-sender",
   "metadata": {},
   "source": [
    "### 23.4.2 函数介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "reduced-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv中使用函数cv2.face.FisherFaceRecognizer_create()生成LBPH识别器实例模型\n",
    "# 然后用cv2.face_FaceRecognizer.train()完成训练\n",
    "# 最后用cv2.face_FaceRecognizer.predict()完成人脸识别\n",
    "\n",
    "# 1.cv2.face.FisherFaceRecognizer_create()\n",
    "# retval = cv2.face.FisherFaceRecognizer_create([,num_components[,threshold]])\n",
    "# num_components：保留的成分数量，可用默认值0，让函数自动设置合适的成分数量\n",
    "# threshold：人脸识别时采用的阈值，如果最近的距离比预设的阈值还要大，函数返回-1\n",
    "\n",
    "# 2.cv2.face_Face_Recognizer.train()\n",
    "# None = cv2.face_Face_Recognizer.train(src,labels)\n",
    "# src：训练图像，用于训练的人脸图像\n",
    "# labels：标签，人脸图所对应的标签\n",
    "\n",
    "# 3.cv2.face_FaceRecognizer.predict()\n",
    "# label,confidence = cv2.face_FaceRecognizer.predict(src)\n",
    "# src：需要识别的人脸图像\n",
    "# label：返回识别结果标签\n",
    "# confidence：置信度评分。衡量识别结果与原有模型间的距离，0表示完全匹配，该参数通常在0-20000之间，低于5000则认为相当可靠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "authentic-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "images = []\n",
    "images.append(cv2.imread('a1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('a2.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b1.png',cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread('b2.png',cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "# 训练集标签\n",
    "labels = [0,0,1,1]\n",
    "\n",
    "# 测试图片\n",
    "predict_iamge = cv2.imread('a3.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "recognizer.train(images,np.array(labels))\n",
    "label,confidence = recognizer.predict(predict_iamge)\n",
    "\n",
    "print(label,confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-hayes",
   "metadata": {},
   "source": [
    "# 23.5 人脸数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "organizational-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.CAS-PEAL\n",
    "# 2.AT&T Facedatabase\n",
    "# 3.Yale Facedatabase A\n",
    "# 4.Extend .Yale Facedatabase B\n",
    "# 5.color FERER database\n",
    "# 6.人脸数据库整理网站：http://face-rec.org/databases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
